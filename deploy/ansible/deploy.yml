# yaml-language-server: $schema=https://json.schemastore.org/ansible-playbook.json

# Install shakenfist on a series of Ubuntu or Debian machines
- hosts: localhost
  gather_facts: yes
  connection: ssh
  become: yes
  vars:
    ram_system_reservation: 5.0

  tasks:
    - name: Set RAM reservation as a var
      set_fact:
        "ram_system_reservation": "{{ram_system_reservation}}"
      delegate_to: localhost
      delegate_facts: true

    - include_tasks: tasks/distro-check.yml

    - name: Generate a random auth secret
      set_fact:
        auth_secret: "{{ lookup('password', '/dev/null length=30 chars=ascii_letters') }}"

    - name: Log topology
      debug:
        msg: "{{topology}}"

    - name: Add nodes from topology
      # This include is to work around the lack of blocks in loops
      include: includes/topology_add_node.yml
      loop: "{{topology}}"

    - name: Set configuration file location
      set_fact:
        "template_path": "/srv/shakenfist/venv/share/shakenfist/templates"
        "utility_path": "/srv/shakenfist/venv/bin"
      delegate_to: localhost
      delegate_facts: true

    - name: Check if we have a venv on localhost already
      stat:
        path: /srv/shakenfist/venv/share/shakenfist/templates
      register: localhost_venv

- hosts: allsf
  any_errors_fatal: true
  become: yes
  become_method: sudo
  gather_facts: no
  connection: ssh

  tasks:
    - name: Setup /etc/hosts
      copy:
        content: |
          127.0.0.1 localhost

          # The following lines are desirable for IPv6 capable hosts
          ::1 ip6-localhost ip6-loopback
          fe00::0 ip6-localnet
          ff00::0 ip6-mcastprefix
          ff02::1 ip6-allnodes
          ff02::2 ip6-allrouters
          ff02::3 ip6-allhosts

          {% for svr in groups.allsf %}
          {{hostvars[svr]['node_mesh_ip']}}  {{svr}}
          {% endfor %}
          {{hostvars[groups['primary_node'][0]]['node_mesh_ip']}}  sf-primary
        dest: /etc/hosts
        owner: root
        group: root
        mode: u=r,g=r,o=r

    - name: Log network and primary node
      debug:
        msg:
          - "Primary node IP is {{hostvars[groups['primary_node'][0]]['node_mesh_ip']}}"
          - "Network node is {{hostvars[groups['network_node'][0]]['node_name']}} with mesh IP {{hostvars[groups['network_node'][0]]['node_mesh_ip']}}"
      run_once: true

    # As recommended on the ansible apt module documentation...
    - name: Upgrade packages
      apt:
        upgrade: dist
        update_cache: yes
        autoremove: yes
      register: apt_action
      retries: 100
      until: apt_action is success or ('Failed to lock apt for exclusive operation' not in apt_action.msg and '/var/lib/dpkg/lock' not in apt_action.msg)

    # We install libvirt, even on non-hypervisors, because we use it to track
    # the CPU topology and load of the node.
    - name: Install non-hypervisor dependencies
      apt:
        name:
          - arping
          - bridge-utils
          - cpu-checker
          - dnsmasq
          - dnsutils
          - hddtemp
          - libmagic-dev
          - libssl-dev
          - libssl-dev
          - libvirt-daemon-system
          - libvirt-dev
          - lm-sensors
          - net-tools
          - ovmf
          - prometheus-node-exporter
          - python3-libvirt
          - python3-venv
          - qemu-kvm
          - unzip
        state: latest

- hosts: hypervisors, network_node
  any_errors_fatal: true
  become: yes
  become_method: sudo
  gather_facts: no
  connection: ssh

  tasks:
    - name: Determine the mesh network interface MTU
      shell: ip link show
      register: ip_links

    - name: Log network interfaces
      debug:
        msg: "{{ip_links.stdout}}"

    - name: Determine the mesh network interface MTU
      shell: ip link show {{node_mesh_nic}} | grep mtu | sed -e 's/.*mtu //' -e 's/ .*//'
      register: node_mtu_complex

    - name: Extract default interface MTU
      set_fact:
        node_mtu: "{{node_mtu_complex.stdout}}"

    - name: Log node MTU
      debug:
        msg: "Node MTU is {{node_mtu}}"

    - name: Abort if default interface MTU is too low
      fail:
        msg: "Node MTU is too low."
      when: ignore_mtu != "1" and node_mtu|int < 2000

    - name: Make /srv/shakenfist/
      file:
        path: /srv/shakenfist
        state: directory
        mode: "0755"

    - name: Install gunicorn
      shell: /srv/shakenfist/venv/bin/pip install -U gunicorn

    - name: Configure IPv6 to be disabled on boot
      copy:
        content: |
          net.ipv6.conf.all.disable_ipv6 = 1
          net.ipv6.conf.default.disable_ipv6 = 1
        dest: /etc/sysctl.d/10-sf-ipv6.conf
        owner: root
        mode: u=r,g=r,o=r

    - name: Configure IPv6 to be disabled now
      shell: |
        sysctl -w net.ipv6.conf.all.disable_ipv6=1
        sysctl -w net.ipv6.conf.default.disable_ipv6=1
      ignore_errors: True

    - name: Configure ipforwarding to be enabled on boot
      copy:
        content: |
          net.ipv4.ip_forward = 1
        dest: /etc/sysctl.d/10-sf-ipforwarding.conf
        owner: root
        mode: u=r,g=r,o=r

    - name: Configure ipforwarding to be enabled now
      shell: |
        sysctl -w net.ipv4.ip_forward=1
      ignore_errors: True

- hosts: hypervisors
  any_errors_fatal: true
  become: yes
  become_method: sudo
  gather_facts: no
  connection: ssh

  tasks:
    - name: Disable dnsmasq
      service:
        name: dnsmasq
        enabled: no
        state: stopped

    - name: Check that we can run KVM
      shell: kvm-ok

    # Determine what architecture we're on. Derived from
    # https://github.com/redhat-openstack/ansible-role-tripleo-parts
    - name: Do we have Intel CPUs?
      command: grep -q Intel /proc/cpuinfo
      ignore_errors: true
      register: is_intel

    - name: Do we have AMD CPUs?
      command: grep -q AMD /proc/cpuinfo
      ignore_errors: true
      register: is_amd

    - name: Enable nested virtualization now (AMD)
      shell: |
        modprobe -r kvm_intel || true
        modprobe kvm_amd nested=1
      when: is_amd.rc == 0

    - name: Enable nested virtualization now (Intel)
      shell: |
        modprobe -r kvm_amd
        modprobe kvm_intel nested=1
      when: is_intel.rc == 0

    - name: Enable nested virtualization on boot (AMD)
      copy:
        content: |
          options kvm_amd nested=1
        dest: /etc/modprobe.d/sf-kvm.conf
        owner: root
        mode: u=r,g=r,o=r
      when: is_amd.rc == 0

    - name: Enable nested virtualization on boot (Intel)
      copy:
        content: |
          options kvm_intel nested=1
        dest: /etc/modprobe.d/sf-kvm.conf
        owner: root
        mode: u=r,g=r,o=r
      when: is_intel.rc == 0

    - name: Configure KSM to run on boot
      copy:
        content: |
          w /sys/kernel/mm/ksm/run - - - - 1
          w /sys/kernel/mm/ksm/pages_to_scan - - - - 1000000
          w /sys/kernel/mm/ksm/merge_across_nodes - - - - 0
        dest: /etc/tmpfiles.d/sf-ksm.conf
        owner: root
        mode: u=r,g=r,o=r
      when: ksm_enabled == "1"

    # merge_across_nodes requires a reboot, so is skipped below
    - name: Configure KSM to run now
      shell: |
        echo "1" > /sys/kernel/mm/ksm/run
        echo "100000" > /sys/kernel/mm/ksm/pages_to_scan
      ignore_errors: True
      when: ksm_enabled == "1"

    - name: Configure KSM to not run on boot
      copy:
        content: |
          w /sys/kernel/mm/ksm/run - - - - 0
          w /sys/kernel/mm/ksm/pages_to_scan - - - - 0
          w /sys/kernel/mm/ksm/merge_across_nodes - - - - 0
        dest: /etc/tmpfiles.d/sf-ksm.conf
        owner: root
        mode: u=r,g=r,o=r
      when: ksm_enabled != "1"

    # merge_across_nodes requires a reboot, so is skipped below
    - name: Configure KSM to not run now
      shell: |
        echo "0" > /sys/kernel/mm/ksm/run
        echo "0" > /sys/kernel/mm/ksm/pages_to_scan
      ignore_errors: True
      when: ksm_enabled != "1"

- hosts: primary_node
  any_errors_fatal: true
  become: yes
  become_method: sudo
  gather_facts: no
  connection: ssh

  tasks:
    - name: Find hypervisor with lowest MTU
      set_fact:
        lowest_mtu_hypervisor: "{{ groups['hypervisors'] | sort('node_mtu' | int) | first }}"

    - name: Find lowest MTU
      set_fact:
        lowest_mtu: "{{ hostvars[lowest_mtu_hypervisor]['node_mtu'] }}"

    - name: Write syslog file
      template:
        src: files/rsyslog-server-01-sf.conf
        dest: /etc/rsyslog.d/01-sf.conf
        owner: root
        group: sudo
        mode: u=r,g=r,o=

    - name: Restart syslog
      service:
        name: rsyslog
        enabled: yes
        state: restarted

- hosts: allsf
  any_errors_fatal: true
  become: yes
  become_method: sudo
  gather_facts: yes
  connection: ssh

  tasks:
    - name: Syslog server is the primary server
      set_fact:
        syslog: "{{hostvars[groups['primary_node'][0]]['node_mesh_ip']}}"

    - name: Send syslog to the primary server, unless I am the primary server
      template:
        src: files/rsyslog-client-01-sf.conf
        dest: /etc/rsyslog.d/01-sf.conf
        owner: root
        group: sudo
        mode: u=r,g=r,o=
      when: hostvars[groups['primary_node'][0]]['node_mesh_ip'] != node_mesh_ip

    - name: Restart syslog
      service:
        name: rsyslog
        enabled: yes
        state: restarted
      when: hostvars[groups['primary_node'][0]]['node_mesh_ip'] != node_mesh_ip

# Install etcd
- hosts: etcd
  roles:
    - role: andrewrothstein.etcd-cluster
      vars:
        etcd_secure: False
        etcd_cluster_name: shakenfist
        etcd_enable_v2: False
        etcd_master_group_name: etcd_master
        etcd_iface_public: "{{node_mesh_nic}}"
        etcd_iface_cluster: "{{node_mesh_nic}}"

- hosts: allsf
  any_errors_fatal: true
  become: yes
  become_method: sudo
  gather_facts: yes
  connection: ssh

  tasks:
    - name: Create storage directory
      file:
        path: /srv/shakenfist
        state: directory
        mode: "0755"

- hosts: primary_node
  any_errors_fatal: true
  become: yes
  become_method: sudo
  gather_facts: no
  connection: ssh

  tasks:
    - name: Create config directory
      file:
        path: /etc/sf
        state: directory
        mode: "0755"

    - name: Restore from backup, if there is one specified
      shell: "{{hostvars['localhost']['utility_path']}}/sf-backup restore {{restore_backup}}"
      when: restore_backup | length > 0

    - name: Set system key from extra-vars
      set_fact:
        system_key: "{{admin_password}}"

    - name: Use Hashicorp Vault for "system" namespace key (if enabled)
      block:
        - set_fact:
            system_key: "{{lookup('hashivault', '{{vault_system_key_path}}', 'key')}}"
          when: vault_system_key_path is defined

      rescue:
        - fail:
            msg: "Ensure that you have installed ansible-modules-hashivault ie. pip install ansible-modules-hashivault"

    - name: Write sfrc file
      template:
        src: files/sfrc
        dest: /etc/sf/sfrc
        owner: root
        group: sudo
        mode: u=r,g=r,o=

    - name: Install sfrc for root user
      lineinfile:
        path: /root/.bashrc
        create: yes
        regexp: ". /etc/sf/sfrc"
        line: ". /etc/sf/sfrc"

    - name: Write a global auth file
      template:
        src: files/shakenfist.json
        dest: /etc/sf/shakenfist.json
        owner: root
        group: sudo
        mode: u=r,g=r,o=

    - name: Install prometheus
      apt:
        name: prometheus
        state: latest

    - name: Write prometheus configuration file
      copy:
        content: |
          global:
            external_labels:
              monitor: 'shakenfist'
              origin_prometheus: {{deploy_name}}

          scrape_configs:
            - job_name: 'node'
              static_configs:
                - targets: [
                      {% for svr in groups.allsf %}
                        '{{hostvars[svr]['node_mesh_ip']}}:9100',
                     {% endfor %}
                    ]
            - job_name: 'shakenfist'
              static_configs:
                - targets: [
                      {% for svr in groups.sf_promethus_exporters %}
                        '{{hostvars[svr]['node_mesh_ip']}}:13001',
                      {% endfor %}
                    ]
                # metric_relabel_configs:
                # - source_labels: [__name__]
                #   regex: '(python\w*|process_\w*)'
                #   action: drop
            - job_name: 'etcd'
              static_configs:
                - targets: [
                      {% for svr in groups.etcd_master %}
                        '{{hostvars[svr]['node_mesh_ip']}}:2379',
                      {% endfor %}
                    ]
                # metric_relabel_configs:
                # - source_labels: [__name__]
                #   regex: (?i)(etcd_mvcc_db_total_size_in_bytes|etcd_network_client_grpc_received_bytes_total|etcd_network_client_grpc_sent_bytes_total|etcd_disk_wal_fsync_duration_seconds)
                #   action: keep
        dest: /etc/prometheus/prometheus.yml
        owner: root
        mode: u=rw,g=r,o=r

    - name: Restart prometheus
      service:
        name: prometheus
        enabled: yes
        state: restarted

    - name: Install Grafana prerequisites
      apt:
        name:
          - apt-transport-https
          - software-properties-common
        update_cache: yes
        state: latest

    - name: Check if grafana packages are already setup
      stat:
        path: /etc/apt/sources.list.d/packages_grafana_com_oss_deb.list
      register: stat_result

    - name: Add Grafana GPG key
      apt_key: url=https://packages.grafana.com/gpg.key
      when: not stat_result.stat.exists

    - name: Add Grafana APT repository
      apt_repository:
        repo: deb [arch=amd64] http://packages.grafana.com/oss/deb stable main
      when: not stat_result.stat.exists

    - name: Install Grafana
      apt:
        name: grafana
        update_cache: yes
        state: latest

    - name: Write grafana config
      template:
        src: files/grafana/grafana.ini
        dest: /etc/grafana/grafana.ini
        owner: root
        mode: u=rw,g=r,o=r

    - name: Write grafana dashboard
      copy:
        src: files/grafana/provisioning/dashboards/shakenfist.json
        dest: /etc/grafana/provisioning/dashboards/shakenfist.json
        owner: root
        mode: u=rw,g=r,o=r

    - name: Write grafana dashboard config
      copy:
        src: files/grafana/provisioning/dashboards/dashboards.yaml
        dest: /etc/grafana/provisioning/dashboards/dashboards.yaml
        owner: root
        mode: u=rw,g=r,o=r

    - name: Write prometheus grafana configuration file
      copy:
        content: |
          apiVersion: 1

          datasources:
          - name: Prometheus
            type: prometheus
            orgId: 1
            url: http://{{node_mesh_ip}}:9090
            isDefault: true
            version: 1
            editable: false
            access: proxy
            jsonData:
              tlsSkipVerify: true
        dest: /etc/grafana/provisioning/datasources/prometheus.yml
        owner: root
        mode: u=rwx,g=r,o=r

    - name: Restart grafana
      service:
        name: grafana-server
        enabled: yes
        state: restarted

    - name: Install apache2
      apt:
        name: apache2
        state: latest

    - name: Enable proxy modules for apache
      shell: a2enmod proxy proxy_http lbmethod_byrequests

    - name: Write apache site
      template:
        src: files/apache-site-primary.conf
        dest: /etc/apache2/sites-available/sf-example.conf
        owner: root
        group: root
        mode: u=r,g=r,o=r

    - name: Reload apache
      shell: apache2ctl graceful

- hosts: hypervisors
  any_errors_fatal: true
  become: yes
  become_method: sudo
  gather_facts: no
  connection: ssh

  tasks:
    - name: Copy libvirt template
      copy:
        src: "{{hostvars['localhost']['template_path']}}/libvirt.tmpl"
        remote_src: yes
        dest: /srv/shakenfist/libvirt.tmpl
        owner: root
        group: root
        mode: "0644"

    - name: Turn off default libvirt networking
      shell: virsh net-destroy default
      ignore_errors: True

    - name: Check that the /etc/apparmor.d/local/abstractions/libvirt-qemu exists
      stat:
        path: /etc/apparmor.d/local/abstractions/libvirt-qemu
      register: stat_result

    # NOTE(mikal): this wont work if the user has configured a different
    # path for the instance path. We should fix that.
    - name: Add an apparmor rule for NVMe disks (modern Debian)
      lineinfile:
        path: /etc/apparmor.d/local/abstractions/libvirt-qemu
        regexp: "/srv/shakenfist/instances.*nvme.*"
        line: "/srv/shakenfist/instances/*/nvme[0-9] rwk,"
      when: stat_result.stat.exists

    # NOTE(mikal): and fix it here too.
    - name: Add an apparmor rule for NVMe disks (older Debian)
      lineinfile:
        path: /etc/apparmor.d/abstractions/libvirt-qemu
        regexp: "/srv/shakenfist/instances.*nvme.*"
        line: "/srv/shakenfist/instances/*/nvme[0-9] rwk,"
      when: not stat_result.stat.exists

    - name: Restart apparmor
      service:
        name: apparmor
        enabled: yes
        state: restarted

- hosts: network_node
  any_errors_fatal: true
  become: yes
  become_method: sudo
  gather_facts: no
  connection: ssh

  tasks:
    - name: Copy dhcp config template
      copy:
        src: "{{hostvars['localhost']['template_path']}}/dhcp.tmpl"
        remote_src: yes
        dest: /srv/shakenfist/dhcp.tmpl
        owner: root
        group: root
        mode: "0644"

    - name: Copy dhcp hosts template
      copy:
        src: "{{hostvars['localhost']['template_path']}}/dhcphosts.tmpl"
        remote_src: yes
        dest: /srv/shakenfist/dhcphosts.tmpl
        owner: root
        group: root
        mode: "0644"

- hosts: hypervisors, network_node, etcd_master
  any_errors_fatal: true
  become: yes
  become_method: sudo
  gather_facts: no
  connection: ssh

  tasks:
    - name: Check if we have an existing config
      stat:
        path: /etc/sf/config
      register: config_stat_result

    - name: Log stat result for existing config
      debug:
        msg: "Existing config: {{config_stat_result}}"

    - name: Fetch config template from remote host
      fetch:
        src: "{{hostvars['localhost']['template_path']}}/config"
        dest: /tmp/{{ansible_host}}_config
        flat: yes
        fail_on_missing: yes
      when: not config_stat_result.stat.exists

    - name: Ensure /etc/sf exists
      file:
        path: /etc/sf
        state: directory
      when: not config_stat_result.stat.exists

    - name: Write config file on remote host
      template:
        src: /tmp/{{ansible_host}}_config
        dest: /etc/sf/config
        owner: root
        group: root
        mode: u=r,g=r,o=r
      when: not config_stat_result.stat.exists

    - name: Fetch systemd unit template from remote host
      fetch:
        src: "{{hostvars['localhost']['template_path']}}/sf.service"
        dest: /tmp/{{ansible_host}}_sf.service
        flat: yes
        fail_on_missing: yes

    - name: Write systemd unit on remote host
      template:
        src: /tmp/{{ansible_host}}_sf.service
        dest: /etc/systemd/system/sf.service
        owner: root
        group: root
        mode: u=r,g=r,o=r

    - name: Remove old systemd units
      file:
        dest: /lib/systemd/system/sf.service
        state: absent

    - name: Ensure /var/run/sf exists
      file:
        path: /var/run/sf
        state: directory
        owner: root
        group: root
        mode: u=rw,g=r,o=r
      when: not config_stat_result.stat.exists

- hosts: hypervisors, network_node, etcd_master
  any_errors_fatal: true
  serial: 1
  become: yes
  become_method: sudo
  gather_facts: no
  connection: ssh

  tasks:
    - name: Restart the SF daemon, one node at a time
      service:
        name: sf
        enabled: yes
        state: restarted
        daemon_reload: yes

- hosts: hypervisors
  any_errors_fatal: true
  become: yes
  become_method: sudo
  gather_facts: no
  connection: ssh

  tasks:
    - name: Create an admin namespace called "system" with one key configured
      shell: "{{hostvars['localhost']['utility_path']}}/sf-ctl bootstrap-system-key deploy {{hostvars[groups['primary_node'][0]]['system_key']}}"
      run_once: true

- hosts: primary_node
  any_errors_fatal: true
  become: yes
  become_method: sudo
  gather_facts: no
  connection: ssh

  tasks:
    - name: Rotate logs and remove old logs
      shell: |
        journalctl --rotate
        journalctl --vacuum-time=2d
        /usr/sbin/logrotate -f /etc/logrotate.conf
      ignore_errors: True

    - name: Clear out old terraform providers
      file:
        path: /srv/shakenfist/terraform-provider-shakenfist
        state: absent

    - name: Make sure we don't have an old provider installed
      file:
        path: /usr/local/bin/terraform_install/terraform-provider-shakenfist
        state: absent

    - name: Make /usr/share/ansible/plugins/modules
      file:
        path: /usr/share/ansible/plugins/modules
        state: directory
        mode: "0755"

    - name: Install ansible instance module
      copy:
        src: /srv/shakenfist/venv/share/shakenfist/ansible/sf_instance.py
        remote_src: yes
        dest: /usr/share/ansible/plugins/modules/sf_instance.py
        owner: root
        group: root
        mode: "0644"

    - name: Install ansible network module
      copy:
        src: /srv/shakenfist/venv/share/shakenfist/ansible/sf_network.py
        remote_src: yes
        dest: /usr/share/ansible/plugins/modules/sf_network.py
        owner: root
        group: root
        mode: "0644"

    - name: Install ansible snapshot module
      copy:
        src: /srv/shakenfist/venv/share/shakenfist/ansible/sf_snapshot.py
        remote_src: yes
        dest: /usr/share/ansible/plugins/modules/sf_snapshot.py
        owner: root
        group: root
        mode: "0644"
